{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "# Plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the folder\n",
    "path = 'C:/Users/prash/Downloads/ML ALGORITHMS/'\n",
    "\n",
    "#labels for discretization\n",
    "labels = ['low','medium','high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Diabetes Dataset\n",
    "diabetes_dataset = pd.read_csv(path + 'DATASETS/' + 'diabetes.csv')\n",
    "\n",
    "# Input Dataframe\n",
    "X = diabetes_dataset.iloc[:,:-1]\n",
    "\n",
    "\n",
    "#Preprocessing\n",
    "for j in X.columns:\n",
    "    mean = X[j].mean()\n",
    "    X[j] = X[j].replace(0,mean)\n",
    "    X[j] = pd.cut(X[j],bins=len(labels),labels=labels)\n",
    "\n",
    "    \n",
    "# Encode the Output labels\n",
    "Y = diabetes_dataset.iloc[:,-1]\n",
    "\n",
    "# Divide into train and test datasets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training :  70.12987012987013\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "def count(X,Y,target,col_index = None,label = None):\n",
    "    if(label != None):\n",
    "        data = [X,Y]\n",
    "        return len(data[0][(data[0].iloc[:,col_index] == label) & (data[1] == target)])\n",
    "    else:\n",
    "        return len(Y[Y == target])\n",
    "\n",
    "# Initializing Necessary Dictionaries\n",
    "probabilities = {}\n",
    "categ_count = {}\n",
    "categ_label_count = {}\n",
    "prob = {}\n",
    "\n",
    "for category in range(np.unique(Y_train).size):\n",
    "    probabilities[category] = {}\n",
    "    categ_count[category] = count(X_train,Y_train,0,category)\n",
    "    prob[category] = categ_count[category]/X_train.shape[0]\n",
    "\n",
    "# Calculating Probabilities for each Category for each Feature and Label\n",
    "for category in range(np.unique(Y_train).size):\n",
    "    for col_index in range(X_train.shape[1]):\n",
    "        probabilities[category][col_index] = {}\n",
    "        for label in labels:\n",
    "            categ_label_count[category] = count(X_train,Y_train,category,col_index,label)\n",
    "            probabilities[category][col_index][label] = categ_label_count[category] / categ_count[category]\n",
    "            \n",
    "# Testing\n",
    "\n",
    "# Calculating Probabilty for each Category and Select the Category which has Max Probabilty\n",
    "predicted = []\n",
    "for row_index in range(X_test.shape[0]):\n",
    "    prod = deepcopy(prob)\n",
    "    for category in range(np.unique(Y_test).size):\n",
    "        for col_index in range(X_test.shape[1]):\n",
    "            label = X_test.iloc[row_index,col_index]\n",
    "            prod[category] *= probabilities[category][col_index][label]\n",
    "    dummy = list(prod.values())\n",
    "    predicted.append(dummy.index(max(dummy)))\n",
    "    \n",
    "\n",
    "# Metrics\n",
    "\n",
    "tp,tn,fp,fn = 0,0,0,0\n",
    "for j in range(0,len(predicted)):\n",
    "    if predicted[j] == 0:\n",
    "        if Y_test.iloc[j] == 0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if Y_test.iloc[j] == 1:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "print('Accuracy for training : ',((tp+tn)/len(Y_test))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7077922077922078\n"
     ]
    }
   ],
   "source": [
    "#creating labelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in range(X.shape[1]):\n",
    "    # Converting string labels into numbers.\n",
    "    X.iloc[:,i] = le.fit_transform(X.iloc[:,i])\n",
    "        \n",
    "# Divide into train and test datasets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# Training\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Testing\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://blog.goodaudience.com/building-the-na%C3%AFve-bayes-classifier-from-scratch-in-python-b0717fa022d8 <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
