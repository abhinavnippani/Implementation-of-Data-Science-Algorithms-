{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.linalg import inv,pinv\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the folder\n",
    "path = 'C:/Users/prash/Downloads/ML ALGORITHMS/'\n",
    "\n",
    "# Number of clusters required\n",
    "k = 3\n",
    "\n",
    "# Number of Neurons in Hidden Layer\n",
    "h = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Iris Dataset\n",
    "iris_dataset = pd.read_csv(path + 'DATASETS/' + 'Iris.csv')\n",
    "# Removing Index Column\n",
    "iris_dataset = iris_dataset.iloc[:,1:]\n",
    "\n",
    "# Input Dataframe\n",
    "X = iris_dataset.iloc[:,:-1]\n",
    "X = np.array(X)\n",
    "\n",
    "# Encode the Output labels\n",
    "Y = iris_dataset.iloc[:,-1]\n",
    "for i in range(len(Y.unique())):\n",
    "    Y = Y.replace(Y.unique()[i],i)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# One Hot Encode the Output Labels\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(Y.reshape(-1,1)).toarray()\n",
    "\n",
    "# Normalize the Dataframe\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divide into train and test datasets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Function\n",
    "def dist(a, b,ax=1):\n",
    "    \n",
    "    # Euclidian Distance\n",
    "    distance = np.sqrt(np.sum((a - b)**2,axis=ax))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "def modified_kmeans(X,k):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Initialize Centroids randomly in C (will contain updated Centroids value)\n",
    "    C = np.random.uniform(0, np.max(X), size=(k,X.shape[1]))\n",
    "\n",
    "    # Store old Centroid values in C_old\n",
    "    C_old = np.zeros(C.shape)\n",
    "\n",
    "    # Initialize target clusters for each instance as 0\n",
    "    clusters = np.zeros(X.shape[0])\n",
    "\n",
    "    # Error - Distance between new centroids and old centroids\n",
    "    error = dist(C, C_old,None)\n",
    "\n",
    "    # Loop will run till the error becomes zero\n",
    "    while error != 0:\n",
    "\n",
    "        # Assigning each value to its closest cluster\n",
    "        for i in range(X.shape[0]):\n",
    "            distances = dist(C, X[i],1)\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster\n",
    "\n",
    "        # Storing the old centroid values\n",
    "        C_old = deepcopy(C)\n",
    "\n",
    "        # Finding the new centroids by taking the mean of all the instances in that cluster\n",
    "        for i in range(k):\n",
    "            points = [X[j] for j in range(X.shape[0]) if clusters[j] == i]\n",
    "            if(len(points) > 0):\n",
    "                C[i] = np.mean(points, axis=0)\n",
    "\n",
    "        # Calculating Error \n",
    "        error = dist(C, C_old,None)\n",
    "    \n",
    "    # Assigning a Cluster for each Instance/Row\n",
    "    I = np.empty([1,m])\n",
    "    for i in range(m):\n",
    "        minim = dist(X[i,:],C[0,:],0)\n",
    "        s=0\n",
    "        for j in range(1,k):\n",
    "            t = dist(X[i,:],C[j,:],0)\n",
    "            if(t<minim):\n",
    "                s = j\n",
    "        I[0,i] = s\n",
    "    \n",
    "    # Calculating mu for each cluster\n",
    "    mu = np.ones([k,n])-1\n",
    "    count = np.ones([k,1])-1\n",
    "    for i in range(m):\n",
    "        for j in range(k):\n",
    "            if(I[0,i]==j):\n",
    "                mu[j,:] = mu[j,:]+X[i,:]\n",
    "                count[j,0] = count[j,0]+1\n",
    "    for i in range(k):\n",
    "        if(count[i,0]!=0):\n",
    "            mu[i,0] = mu[i,0]/count[i,0]\n",
    "\n",
    "    # Calculating sigma for each cluster \n",
    "    sigma = np.ones([k,n])-1\n",
    "    for i in range(m):\n",
    "        for j in range(k):\n",
    "            if(I[0,i]==j):\n",
    "                sigma[j,:] = sigma[j,:] + np.square(X[i,:] - mu[j,:])\n",
    "    for i in range(k):\n",
    "        if(count[i,0]!=0):\n",
    "            sigma[i,0] = sigma[i,0]/count[i,0]\n",
    "    sigma = np.sqrt(sigma)\n",
    "    \n",
    "    # Calculating beta for each cluster\n",
    "    beta = np.ones([k,n])-1\n",
    "    for i in range(k):\n",
    "        if(count[i,0]!=0):\n",
    "            beta[i,:] = 1/(2 * np.square(sigma[i,:]))\n",
    "     \n",
    "    \n",
    "    return beta,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Beta Values are:\n",
      "\n",
      " [[2.06487064e+00 1.03519069e-05 8.93462496e-05 1.33238027e-04]\n",
      " [2.83196225e+00 1.72631401e-05 5.62765899e-06 5.97779790e-06]\n",
      " [1.26485918e+00 2.09626243e-04 7.15440541e-06 6.53039348e-06]]\n",
      "\n",
      "Obtained Mu Values are:\n",
      "\n",
      " [[ -0.0991091  -36.11274674  12.28981595  10.06031167]\n",
      " [ -1.01866041  28.34223517 -49.66044019 -48.18396703]\n",
      " [  1.11690477   7.5853892   41.27161154  43.198512  ]]\n",
      "\n",
      "The Weights Obtained are:\n",
      "\n",
      " [[ 0.02457132  0.65149213  0.064032  ]\n",
      " [ 1.00070152  0.01975333  0.00230499]\n",
      " [-0.0052479   0.19162741  0.92427988]]\n",
      "\n",
      "The Final Accuracy Obtained is:\n",
      "\n",
      " 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Beta and Mu Parameters\n",
    "beta,mu = modified_kmeans(X_train,h)\n",
    "print('Obtained Beta Values are:\\n\\n',beta)\n",
    "print('\\nObtained Mu Values are:\\n\\n',mu)\n",
    "\n",
    "# Remove unnecessary centroids \n",
    "mu_sum = np.sum(mu,axis=1)\n",
    "for j in range(10):\n",
    "    for i in range(mu_sum.size):\n",
    "        if(mu_sum[i]==0):\n",
    "            mu = np.delete(mu,i,0)\n",
    "            beta = np.delete(beta,i,0)\n",
    "            mu_sum=np.delete(mu_sum,i,0)\n",
    "            h = h-1\n",
    "            break\n",
    "\n",
    "\n",
    "# Calculating the Values in Hidden Layer\n",
    "m = X_train[:,0].size\n",
    "H_train = np.empty([m,h])\n",
    "for i in range(m):\n",
    "    for j in range(h):\n",
    "        H_train[i,j] = np.exp(-1*np.dot(beta[j],np.square(X_train[i] - mu[j])))\n",
    "\n",
    "# Calculating the weights        \n",
    "W = np.dot(pinv(H_train),Y_train)\n",
    "print('\\nThe Weights Obtained are:\\n\\n',W)\n",
    "\n",
    "\n",
    "# Calculating the same for Test Values\n",
    "\n",
    "m = X_test[:,0].size\n",
    "H_test = np.empty([m,h])\n",
    "for i in range(m):\n",
    "    for j in range(h):\n",
    "        H_test[i,j] = np.exp(-1*np.dot(beta[j],np.square(X_test[i] - mu[j])))\n",
    "        \n",
    "# Predicting the Clusters        \n",
    "Y_pred = np.dot(H_test, W)\n",
    "Y_pred = enc.fit_transform(Y_pred.argmax(axis=1).reshape(-1,1)).toarray()\n",
    "\n",
    "# Finding the accuracy\n",
    "print('\\nThe Final Accuracy Obtained is:\\n\\n',accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "https://towardsdatascience.com/most-effective-way-to-implement-radial-basis-function-neural-network-for-classification-problem-33c467803319 <br>\n",
    "https://mccormickml.com/2013/08/15/radial-basis-function-network-rbfn-tutorial/ <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
