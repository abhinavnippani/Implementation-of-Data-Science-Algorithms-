{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy Statistical Methods\n",
    "from numpy.linalg import svd\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the folder\n",
    "path = 'C:/Users/prash/Downloads/ML ALGORITHMS/'\n",
    "\n",
    "# Number of final features required\n",
    "pca_features = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Breast Cancer Dataset\n",
    "data = pd.read_csv(path + 'DATASETS/' + 'breast_cancer_wisconsin.csv')\n",
    "\n",
    "# drop last column (extra column added by pd and unnecessary first column (id)\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "\n",
    "# convert categorical labels to numbers\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "\n",
    "# put features & outputs in different data frames\n",
    "Y = data.loc[:, 'diagnosis']\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Compute the mean of the data\n",
    "mean_vec = np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch - Eigen Value Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Features obtained from Eigen Value Method are:\n",
      "\n",
      " [[ 9.19283683  1.94858307 -1.12316616]\n",
      " [ 2.3878018  -3.76817174 -0.52929269]\n",
      " [ 5.73389628 -1.0751738  -0.55174759]\n",
      " ...\n",
      " [ 1.25617928 -1.90229671  0.56273053]\n",
      " [10.37479406  1.67201011 -1.87702933]\n",
      " [-5.4752433  -0.67063679  1.49044308]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the covariance matrix\n",
    "cov_mat = (X - mean_vec).T.dot((X - mean_vec)) / (X.shape[0]-1)\n",
    "\n",
    "# Compute the eigen values and vectors using numpy\n",
    "eig_vals, eig_vecs = eig(cov_mat)\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "      \n",
    "        \n",
    "# Compute the projection matrix based on the top eigen vectors\n",
    "num_features = X.shape[1]\n",
    "proj_mat = eig_pairs[0][1].reshape(num_features,1)\n",
    "\n",
    "for eig_vec_idx in range(1, pca_features):\n",
    "    proj_mat = np.hstack((proj_mat, eig_pairs[eig_vec_idx][1].reshape(num_features,1)))\n",
    "\n",
    "# Project the data \n",
    "X_pca_eigen = X.dot(proj_mat)\n",
    "\n",
    "print('The New Features obtained from Eigen Value Method are:\\n\\n',X_pca_eigen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch - Singular Value Decomposition (SVD) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Features obtained from SVD Method are:\n",
      "\n",
      " [[ -9.19283683  -1.94858307  -1.12316616]\n",
      " [ -2.3878018    3.76817174  -0.52929269]\n",
      " [ -5.73389628   1.0751738   -0.55174759]\n",
      " ...\n",
      " [ -1.25617928   1.90229671   0.56273053]\n",
      " [-10.37479406  -1.67201011  -1.87702933]\n",
      " [  5.4752433    0.67063679   1.49044308]]\n"
     ]
    }
   ],
   "source": [
    "# Getting Singular Vectors U,V and Singular Values S through Numpy's svd method\n",
    "U,s,vt = svd((X - mean_vec), full_matrices = False)\n",
    "\n",
    "# Converting s into a diagonal matrix\n",
    "S = np.diag(s)\n",
    "\n",
    "# Calculating the New Features\n",
    "X_pca_svd = U[:,:pca_features].dot(S[:pca_features,:pca_features])\n",
    "\n",
    "print('The New Features obtained from SVD Method are:\\n\\n',X_pca_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Features obtained from Scikit Learn Method are:\n",
      "\n",
      " [[ 9.19283683  1.94858307 -1.12316616]\n",
      " [ 2.3878018  -3.76817174 -0.52929269]\n",
      " [ 5.73389628 -1.0751738  -0.55174759]\n",
      " ...\n",
      " [ 1.25617928 -1.90229671  0.56273053]\n",
      " [10.37479406  1.67201011 -1.87702933]\n",
      " [-5.4752433  -0.67063679  1.49044308]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the scikit learn model\n",
    "pca = PCA(n_components = pca_features) \n",
    "\n",
    "# Fitting the model to the dataset\n",
    "pca.fit((X-mean_vec)) \n",
    "\n",
    "# Transforming the dataset to get new features\n",
    "X_pca_sklearn = pca.transform(X) \n",
    "\n",
    "print('The New Features obtained from Scikit Learn Method are:\\n\\n',X_pca_eigen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "https://towardsdatascience.com/principal-component-analysis-your-tutorial-and-code-9719d3d3f376 <br>\n",
    "https://towardsdatascience.com/dive-into-pca-principal-component-analysis-with-python-43ded13ead21 <br>\n",
    "https://www.analyticsvidhya.com/blog/2019/08/5-applications-singular-value-decomposition-svd-data-science/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
