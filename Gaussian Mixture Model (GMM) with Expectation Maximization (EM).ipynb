{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "# Plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the folder\n",
    "path = 'C:/Users/prash/Downloads/ML ALGORITHMS/'\n",
    "\n",
    "# Number of clusters required\n",
    "k = 3\n",
    "\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Iris Dataset\n",
    "iris_dataset = pd.read_csv(path + 'DATASETS/' + 'Iris.csv')\n",
    "# Removing Index Column\n",
    "iris_dataset = iris_dataset.iloc[:,1:]\n",
    "\n",
    "# Input Dataframe\n",
    "X = iris_dataset.iloc[:,:-1]\n",
    "X = np.array(X)\n",
    "\n",
    "# Normalize the Dataframe\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Encode the Output labels\n",
    "Y = iris_dataset.iloc[:,-1]\n",
    "for i in range(len(Y.unique())):\n",
    "    Y = Y.replace(Y.unique()[i],i)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Divide into train and test datasets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X,mu,sigma,phi,k):\n",
    "    \n",
    "    n, m = X.shape\n",
    "    \n",
    "    # Calculate Gaussian Distributions and Likelihoods for all the classes\n",
    "    likelihood = np.zeros((n,k))\n",
    "    for i in range(k):\n",
    "        distribution = multivariate_normal(mean = mu[i], cov = sigma[i])\n",
    "        likelihood[:,i] = distribution.pdf(X)\n",
    "    \n",
    "    # Probability of Each Class\n",
    "    numerator = likelihood * phi\n",
    "    # Sum of all Probabilities\n",
    "    denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    weights = numerator / denominator\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def e_step(X,mu,sigma,phi,k):\n",
    "    weights = predict_proba(X,mu,sigma,phi,k)\n",
    "    phi = weights.mean(axis=0)\n",
    "    \n",
    "    return weights,phi\n",
    "    \n",
    "def m_step(X,weights):\n",
    "    for i in range(k):\n",
    "        weight = weights[:, [i]]\n",
    "        total_weight = weight.sum()\n",
    "        \n",
    "        mu[i] = (X * weight).sum(axis=0) / total_weight\n",
    "        sigma[i] = np.cov(X.T, aweights=(weight/total_weight).flatten(), bias=True)\n",
    "        \n",
    "        return mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained parameters are:\n",
      "\n",
      "Phi:\n",
      "\n",
      " [0.62212826 0.17086601 0.20700573]\n",
      "\n",
      "mu:\n",
      "\n",
      " [array([0.56593565, 0.37610181, 0.68064027, 0.68362035]), array([0.08333333, 0.5       , 0.06779661, 0.04166667]), array([0.13888889, 0.41666667, 0.06779661, 0.        ])]\n",
      "\n",
      "sigma:\n",
      "\n",
      " [array([[0.03543998, 0.01463193, 0.02240035, 0.02065583],\n",
      "       [0.01463193, 0.02020826, 0.01006346, 0.0135697 ],\n",
      "       [0.02240035, 0.01006346, 0.01934445, 0.01999573],\n",
      "       [0.02065583, 0.0135697 , 0.01999573, 0.02982374]]), array([[ 0.05580579, -0.00257483,  0.06258859,  0.06329843],\n",
      "       [-0.00257483,  0.03238601, -0.02055817, -0.01894744],\n",
      "       [ 0.06258859, -0.02055817,  0.09152202,  0.09476417],\n",
      "       [ 0.06329843, -0.01894744,  0.09476417,  0.10468592]]), array([[ 0.05580579, -0.00257483,  0.06258859,  0.06329843],\n",
      "       [-0.00257483,  0.03238601, -0.02055817, -0.01894744],\n",
      "       [ 0.06258859, -0.02055817,  0.09152202,  0.09476417],\n",
      "       [ 0.06329843, -0.01894744,  0.09476417,  0.10468592]])]\n",
      "\n",
      "Test set accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Parameters\n",
    "\n",
    "n, m = X_train.shape\n",
    "\n",
    "phi = np.full(shape = k, fill_value = 1/k)\n",
    "\n",
    "random_row = np.random.randint(low = 0, high = n, size = k)\n",
    "mu = [X_train[row_index,:] for row_index in random_row]\n",
    "sigma = [np.cov(X_train.T) for _ in range(k)]\n",
    "\n",
    "# Train\n",
    "\n",
    "for iteration in range(max_iter):\n",
    "    weights,phi = e_step(X_train,mu,sigma,phi,k)\n",
    "    mu,sigma = m_step(X_train,weights)\n",
    "    \n",
    "print(\"The trained parameters are:\")\n",
    "print(\"\\nPhi:\\n\\n\",phi)\n",
    "print(\"\\nmu:\\n\\n\",mu)\n",
    "print(\"\\nsigma:\\n\\n\",sigma)\n",
    "    \n",
    "# Test\n",
    "    \n",
    "weights = predict_proba(X_test,mu,sigma,phi,k)\n",
    "Y_pred = np.argmax(weights, axis=1)\n",
    "\n",
    "# Make sure that the clusters represented in both Y_test and Y_pred are the same\n",
    "permutation = []\n",
    "for i in range(k):\n",
    "    dummy = Y_test[Y_pred == i]\n",
    "    if(dummy.size > 0):\n",
    "        permutation.append(mode(dummy).mode.item())\n",
    "        \n",
    "    # Not sure about this\n",
    "    else:\n",
    "        permutation.append(0)\n",
    "permutation = np.array(permutation)\n",
    "permuted_prediction = permutation[Y_pred]\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(permuted_prediction, Y_test)\n",
    "print(\"\\nTest set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "gmm.fit(X_train)\n",
    "\n",
    "Y_pred = gmm.predict(X_test)\n",
    "\n",
    "# Make sure that the clusters represented in both Y_test and Y_pred are the same\n",
    "permutation = np.array([mode(Y_test[Y_pred == i]).mode.item() for i in range(k)])\n",
    "permuted_prediction = permutation[Y_pred]\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(permuted_prediction, Y_test)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "http://www.oranlooney.com/post/ml-from-scratch-part-5-gmm/\n",
    "https://medium.com/@siddharthvadgama/gaussian-mixture-model-gmm-using-em-algorithm-from-scratch-6b7c764aac9f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
